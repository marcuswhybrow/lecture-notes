.. _G54ACCu06:

=================
06 - Applications
=================

The layers above the transport layer...

Higher Layers
=============

Session and Presentation
************************

Session layer provides the opening an closing of semi-permanent dialogue. For example opening ssh connections.

The presentation layer handles conversion of data encodings.

THey are not traditionally considered as part of the TCP/IP stack. The functions still exist but are not explicitly layered, generally being lumped in together in the *application layer*.

HTTP
====

HyperText Transport Protocol, is a client-server request-response protocol.

There are 4 actors in a HTTP environment:

* **Objects** - named via URIs (URLs)
* **Clients** - know as *user agents* the retrieve objects from ...
* **Servers** - store or generate objects
* **Proxies** - provide feature like caching, logging and transcoding (sometimes get in the way.)

Objects
*******

Used to be just static HTML (HyperText Markup Language) pages and these days can be just about anything. They are labeled via a Uniform Resource Identifier, but on the web this is a Uniform Resource Locator of the format::

    scheme://host:port/path/to/resource?query

Rarely and object could be identified by a Uniform Resource Name::

    urn:ietf:rfc:3986

Requests
********

Connect to a server using TCP on port 80, a request may issue a *GET*, *POST* or *HEAD* (there are others) to the server. It can also specify headers.

Further requests may be required.

Responses
*********

A response contains headers: providing meta-data such as location, type, mtime, length etc. and also content from disk or generated on the fly.

There are no server-side links between requests, so we say that responses are stateless.

Handling State
**************

State is necessary for some applications. For example logging into websites and viewing multiple pages, having a persistent shopping cart, preferences, usage tracking etc.

So to save state the server lets the client to the hard work, avoiding server scaling issues using cookies. A cookie is a small chunk of data which the client stores and returns to the server when sending requests in the future.

Network Usage
*************

Creating a separate TCP connection per request is pretty wasteful.

* It's inefficient if objects are retrieved one at a time.
* Its unfair if requests are handled in parallel.
* Inefficient due to TCP overheads.

HTTP/1.1 added persistent connections which meant multiple requests could be made on a single TCP connection. Although this still leads to scheduling issues.

XMPP
====

EXtensible Messaging & Presence Protocol was the basis for Jabber and Google Talk. The core provides XML streaming for messages and presence.

Extensions are available for HTTP binding, real-time media signalling, multi-user chat, publish-subscribe etc.

Actors
******

Like HTTP there are several actors in XMPP:

* **Clients** - connect to ...
* **Servers** - which may interconnect directly to other networked servers since they can route messages, typically multiplexed over a single TCP connection.
* **Gateways** - connect foreign clients to the XMPP network. For example a Skype gateway into a Google Talk session.

The address format is called a JID (Jabber ID) and looks like this::

    node@domain/resource

and communications can be made secure via TLS.

Protocol
********

The protocol works by exchanging streams of XML using multiple XML *stanzas* which are encapsulated in a single stream.

Three types of stanza are defined:

* **message** - push information
* **presence** - expresses availability and negotiates subscriptions
* **iq** - Request-Response

Extensions: BOSH
****************

Administered by the XMPP Foundation (http://xmpp.org/extensions/), Bidirectional streams Over Synchronous HTTP or BOSH was firewall friendly (using TCP over port 80). It provides free compression (since most servers support Gzip) and hides unreliability (since it emulates long-lived connections by a sequence of request-responses).

The first naive approach required a client to poll the server periodically for data. This meant high latency and bandwidth and battery wastage, which matters especially on mobile clients.

A better way was developed where clients send new requests on receipt of a response. The server always has an outstanding connection which it can push data down. This works well with HTTP/1.1 and not so bad with HTTP/1.0

Corner Cases
************

If a clients gets new data, the existing connection is blocked at the server. So a new connection would have to be opened to send, causing the server to close the old one.

If nothing happens for several minutes a *keepalive* is needed, where the server returns an empty response and the client sends a new empty request.

A constrained client can't do HTTP/1.1 or multiple connections and must revert back to the naive polling mode.

Radically Different
===================

Peer-to-peer (P2P)
******************

Both previous protocols were client-server protocols. If there was a bottleneck at the server or the server is unavailable?

An alternative is peer-to-peer systems. For example CAN, CHORD, Pastry, BitTorrent and KaZaA are all peer-to-peer protocols. There are no *designed* central points (however consider the BitTorrent *tracker* which breaks this slightly) and the protocol is typically self-organising.

Often P2P protocols provide a *distributed hash table* abstraction (Whatever that is).

BitTorrent
**********

BitTorrent distributes the load away from a single source site. FIles are divided into *pieces*, and are obtained separately in a random order trying to keep the *file* live. Each piece has a hash to provide integrity.

A *torrent descriptor* file is made available to a *seed*. THe *tracker* knows who's participating in a given torrent and the clients contac the tracker in order to obtain the list of peers.

The client then connects to other peers and then starts downloading the pieces of the file. BitTorrent is potentially unfair since it used many TCP connections to download a single file.

Common P2P Issues
*****************

* "Seeding the swarm", problems of flash crowds.
* Making net-admins angry, since we are breaking usage models.
* There is no anonymity, so it leaves you open to attack.
* Metadata has no validity, for example a torrent may be a virus and not an MP3.
* Leeching, what are the incentives for peers to share, polices have to be invented to penalise newcomers and rewards clients who contribute.

Active Networks
***************

And now for something completely different (depending on how you look at it). The network considers packets to be passive - routers and middleboxes just store and forward (possibly with a bit of rewriting the packet or triggering a response).

But what about if each packet was a bit of code? Routers could execute a packet (possible controlled by the header). It is an interesting research idea but it never really took off. There is lots of cool stuff about constraining the runtime environment, proving properties on the code etc.